# -*- coding: utf-8 -*-
"""student performance

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kjT9F8jCLfJM-8FQ0m3pZVDlS4XVTmPn
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy  as np
import plotly
import os
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

data=pd.read_csv('/content/student_data.csv')
data

data.head()

data.shape

#check missing values
data.isna().sum()

#check duplicates
data.duplicated().sum()

#check data types
data.describe()

#no of  unique valuees of each column
data.nunique()

grad_mean= (data.G1 + data.G2 + data.G3) / 3
data['G_Mean'] = grad_mean
data.head(7)

data.boxplot(x=data['Mjob'], y = data['G_Mean'], color=data['Mjob'], height=330, width=800, title="occupation of Mother VS Average grade")

plt.figure(figsize=(20,20))
sns.heatmap(data.corr(), vmin=-1, cmap="plasma_r", annot=True)
plt.show()

plt.figure(figsize=(9,5))
sns.countplot(x='Fjob', data = data, palette='dark', saturation=0.9).set(title='Datasets divided by occupation of Father')
plt.show()

#model building
X = data.drop(['Medu', 'Fedu'], axis=1)
y = data[['Fedu','Medu']]

#normalization
from sklearn.preprocessing import MinMaxScaler
minmax = MinMaxScaler()

#fit and transform the data
sk_minmax =  minmax.fit_transform(data[['age']])
sk_minmax.size

# adding it to dataframe
data['minmax_sk'] = pd.Series(sk_minmax.flatten(), index=data.index)

#you can see that both ways yield the same result:
data.loc[:,['age', 'Fedu']].hist(bins=30, figsize=(10,4))
plt.title('minmax sklearn')
plt.show()

data = data[['G1','G2','G3','age','studytime','failures','absences']]
data.head()

#Based on these attributes we want to predic the students finaal Grade(G3)
#Next step is to divide the data into X "features"(explanatory variables) and Y, "target"(response variable)
predict = 'G3'
x = np.array(data.drop([predict],1))
y = np.array(data[predict])

#Split the dataset into Training set and test set
import sklearn
from sklearn import linear_model
x_train, x_test, y_train, y_test= sklearn.model_selection.train_test_split(x,y,test_size = 0.2,random_state = 20)

#Fit the linear regression model to the training set
regressor = linear_model.LinearRegression()
regressor.fit(x_train,y_train)

accuracy = regressor.score(x_test,y_test)
print(accuracy)

from sklearn.tree import DecisionTreeClassifier

model = DecisionTreeClassifier(criterion='gini',max_depth=20,random_state=33) #criterion can be entropy
model.fit(x_train, y_train)

print('model Train Score is : ' , model.score(x_train, y_train))

y_test = model.predict(x_test)
print('model test Score is : ' , model.score(x_test, y_test))